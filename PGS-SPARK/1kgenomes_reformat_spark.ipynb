{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07bfb30d",
   "metadata": {},
   "source": [
    "# Reformat 1kgenome vcf format to vsf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eecc97",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71098aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/09 09:42:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/01/09 09:42:52 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import pyspark\n",
    "\n",
    "# ask Zhong for the keys\n",
    "aws_access_key_id = ''\n",
    "aws_secret_access_key = ''\n",
    "\n",
    "spark = (SparkSession \n",
    "            .builder \n",
    "            .appName(\"1kgenome\") \n",
    "            .master('local[72]')\n",
    "            .config('spark.executor.heartbeatInterval', '1000s')\n",
    "            .config('spark.network.timeout', '10000s')\n",
    "            .config('spark.executor.memory', '4000G')\n",
    "            .config('spark.executor.extraJavaOptions','-Dcom.amazonaws.services.s3.enableV4=true')\n",
    "            .config('spark.driver.extraJavaOptions', '-Dcom.amazonaws.services.s3.enableV4=true')\n",
    "            .config('spark.kryoserializer.buffer.max', '1G') # higher causes oom （GC limit）\n",
    "            .config('spark.local.dir','/mnt/data/spark') # /tmp might be full\n",
    "            .config('spark.sql.autoBroadcastJoinThreshold', '-1')\n",
    "            .getOrCreate()\n",
    "        )\n",
    "sc = spark.sparkContext\n",
    "sc.setSystemProperty('com.amazonaws.services.s3.enableV4', 'true')\n",
    "\n",
    "hadoopConf = sc._jsc.hadoopConfiguration()\n",
    "hadoopConf.set('fs.s3a.access.key', aws_access_key_id)\n",
    "hadoopConf.set('fs.s3a.secret.key', aws_secret_access_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b125d5d7",
   "metadata": {},
   "source": [
    "## 0. Formatting DBSNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db7962b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "# assuming dbsnp database has been downloaded here\n",
    "path = 's3a://zhong-active/PGS/dbsnp328/'\n",
    "\n",
    "dbsnps = [\n",
    "    {'vcf': path + 'GRCh37.gz', 'out': path + 'dbsnp328_grc37_p13.pq'},\n",
    "    {'vcf': path + 'GRCh39.gz', 'out': path + 'dbsnp328_grc38_p13.pq'},\n",
    "]\n",
    "\n",
    "def dbsnp_vcf_to_parquet(dbsnp, parquet_file, partitions=200):\n",
    "    vcf = (spark\n",
    "         .read\n",
    "         .csv(dbsnp, sep='\\t', header=None, comment='#')\n",
    "         .toDF('chr', 'pos', 'rsID', 'ref', 'alt', 'q1', 'q2', 'annot')\n",
    "         .select(\n",
    "           F.regexp_extract('chr', r'NC_0+(\\d+).', 1).astype('int').alias('chr'),\n",
    "           F.col('pos').astype('long'),\n",
    "           F.regexp_extract('rsID', r'rs(\\d+)', 1).astype('long').alias('rsID'),\n",
    "           F.posexplode(F.split(F.concat_ws(',', 'ref', 'alt'), ',')).alias('code', 'allele')                         \n",
    "         )\n",
    "         .drop_duplicates(['chr', 'pos', 'allele', 'rsID'])\n",
    "         .where(F.col('chr')>0)         \n",
    "        )\n",
    "    vcf.repartition(partitions).write.mode('overwrite').parquet(parquet_file)\n",
    "    \n",
    "for dbsnp in dbsnps:\n",
    "    dbsnp_vcf_to_parquet(dbsnp['vcf'], dbsnp['out'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0902b77d",
   "metadata": {},
   "source": [
    "## 1. Combine chromosomal VCFs into a spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d15940f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7b9e231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1000 genomes on S3\n",
    "data_path ='s3a://1000genomes/release/20130502/'\n",
    "prefix = 'ALL.chr'\n",
    "suffix = '.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz'\n",
    "chroms = [data_path + prefix + str(c) + suffix for c in range(1, 23)] \n",
    "chrY = data_path + 'ALL.chrY.phase3_integrated_v1b.20130502.genotypes.vcf.gz'\n",
    "chrX = data_path + 'ALL.chrX.phase3_shapeit2_mvncall_integrated_v1b.20130502.genotypes.vcf.gz'\n",
    "chroms = chroms + [chrX, chrY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cadfb5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change chromosome# to numerical ID, using GRC37 specification\n",
    "mapping = {\n",
    "  'X': '23',\n",
    "  'Y': '24',\n",
    "  'M': '25'\n",
    "}\n",
    "mapping.update({str(i+1):str(i+1) for i in range(22)})\n",
    "# other chromosomes will throw out errors later\n",
    "apply_mapping_udf = F.udf(lambda x: mapping.get(x, x))\n",
    "\n",
    "\n",
    "def get_vcf_headers(vcf, numHeaderLines=1000):\n",
    "    \"\"\"\n",
    "    column headers of vcf files\n",
    "    \"\"\"\n",
    "    return (spark\n",
    "            .read\n",
    "            .csv(vcf, sep='\\n', header=None)\n",
    "            .limit(numHeaderLines)\n",
    "            .where(F.substring('_c0', 1, 6) == '#CHROM')\n",
    "            .collect()[0]['_c0'][1:]\n",
    "            .split('\\t')\n",
    "    )\n",
    "def chr_vcf_to_spark_df(vcfs, limit=0):\n",
    "    \"\"\"\n",
    "    combine a list of vcf files (one per chromosome) into one spark df\n",
    "    set limit to a small number to debug\n",
    "    \"\"\"\n",
    "    all_vcf = None\n",
    "    for chrom in vcfs:\n",
    " #       print(\"Adding \" + chrom)\n",
    "        headers = get_vcf_headers(chrom)\n",
    "        if limit>0:\n",
    "            vcf_c = spark.read.csv(chrom, comment='#', sep='\\t', header=None).limit(limit).toDF(*headers)\n",
    "        else:\n",
    "            vcf_c = spark.read.csv(chrom, comment='#', sep='\\t', header=None).toDF(*headers)\n",
    "        # do a count to force read the file, otherwise headers will be changed\n",
    " #       print(\"Adding %d records.\" % vcf_c.count())\n",
    "        if all_vcf is None:\n",
    "            all_vcf = vcf_c\n",
    "        else:\n",
    "            all_vcf = all_vcf.unionByName(vcf_c, allowMissingColumns=True)  \n",
    "    # change letter chromosome IDs to numerical\n",
    "    print(\"Totally we added %d records.\" % all_vcf.count())\n",
    "    all_vcf = all_vcf.withColumn('CHROM', apply_mapping_udf('CHROM').astype('int'))\n",
    "    return all_vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10fd1108",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/15 16:11:06 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/15 16:14:15 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totally we added 84801880 records.\n"
     ]
    }
   ],
   "source": [
    "all_vcf = chr_vcf_to_spark_df(chroms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928d1275",
   "metadata": {},
   "source": [
    "## 2. Assign SNPid from dbSNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ded626d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbsnp = 's3a://zhong-active/PGS/dbsnp328/dbsnp328_grc37_p13.pq'\n",
    "\n",
    "dbsnp = (spark\n",
    "       .read\n",
    "       .parquet(dbsnp)\n",
    "       .select(F.col('chr').alias('CHROM'), F.col('pos').alias('POS'), F.col('rsID').alias('ID'))\n",
    "       .drop_duplicates(['CHROM', 'POS'])\n",
    "      )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0d03e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vcf = (all_vcf\n",
    "        .withColumnRenamed('ID', 'oldID')\n",
    "        .join(dbsnp, on=['CHROM', 'POS'], how='left')\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634b39e8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/15 16:19:46 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 124:>                                                       (0 + 0) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/15 16:20:00 WARN DAGScheduler: Broadcasting large task binary with size 22.7 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python3: /home/zhongw/.conda/envs/pyspark/bin/../lib/libuuid.so.1: no version information available (required by /lib64/libndctl.so.6)\n",
      "python3: /home/zhongw/.conda/envs/pyspark/bin/../lib/libuuid.so.1: no version information available (required by /lib64/libdaxctl.so.1)\n",
      "python3: /home/zhongw/.conda/envs/pyspark/bin/../lib/libuuid.so.1: no version information available (required by /lib64/libblkid.so.1)\n",
      "[Stage 124:========================>                             (11 + 13) / 24]\r"
     ]
    }
   ],
   "source": [
    "# takes a long time ~3 days\n",
    "all_vcf.repartition(200).write.mode('overwrite').parquet('1kgenome_dbSNP328.pq')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2177f28e",
   "metadata": {},
   "source": [
    "## 3.Covert genotypes to sparse format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c39fd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import pyspark.sql.functions as F\n",
    "genomes = spark.read.parquet('1kgenome_dbSNP328.pq')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18e9c156",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+-----+---------+---+---+\n",
      "|CHROM|      POS|oldID|       ID|REF|ALT|\n",
      "+-----+---------+-----+---------+---+---+\n",
      "|   23| 58310816|    .|767511503|  G|  C|\n",
      "|   23|100682653|    .|782358386|  G|  A|\n",
      "|   23| 85977482|    .|749600777|  G|  T|\n",
      "|   23| 79606493|    .|776730835|  G|  A|\n",
      "|   23| 74469398|    .|758530346|  G|  A|\n",
      "+-----+---------+-----+---------+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "genomes.where(F.col('ID') != F.col('oldID')).select('CHROM', 'POS', 'oldID', 'ID','REF', 'ALT').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73d50ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:=====================================================> (269 + 6) / 275]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+---+---+---+\n",
      "|CHROM|POS|oldID| ID|REF|ALT|\n",
      "+-----+---+-----+---+---+---+\n",
      "+-----+---+-----+---+---+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# sanity check for ID assignment\n",
    "genomes.where((F.col('oldID')!= '.') & (F.col('ID') != F.col('oldID'))).select('CHROM', 'POS', 'oldID', 'ID','REF', 'ALT').show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d688462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2504"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = genomes.columns[9:-1]\n",
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7d10d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NA21144'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a16792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split alleles\n",
    "\n",
    "a1 = (genomes\n",
    "      .select(\n",
    "        'ID',\n",
    "        *((F.split(c, '\\|').getItem(0).astype('int').alias(c) for c in samples))\n",
    "      )\n",
    "      .fillna(0)\n",
    "      .withColumn('gts', F.array(*samples))\n",
    "      .select('ID', 'gts')\n",
    "     )\n",
    "\n",
    "a2 = (genomes\n",
    "      .select(\n",
    "        'ID',\n",
    "        *((F.split(c, '\\|').getItem(1).astype('int').alias(c) for c in samples))\n",
    "      )\n",
    "      .fillna(0)\n",
    "      .withColumn('gts', F.array(*samples))\n",
    "      .select('ID', 'gts')\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5f66845",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python3: /home/zhongw/.conda/envs/pyspark/bin/../lib/libuuid.so.1: no version information available (required by /lib64/libndctl.so.6)\n",
      "python3: /home/zhongw/.conda/envs/pyspark/bin/../lib/libuuid.so.1: no version information available (required by /lib64/libdaxctl.so.1)\n",
      "python3: /home/zhongw/.conda/envs/pyspark/bin/../lib/libuuid.so.1: no version information available (required by /lib64/libblkid.so.1)\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/09 09:44:13 WARN DAGScheduler: Broadcasting large task binary with size 1003.9 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                       (0 + 72) / 400]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/09 09:44:56 ERROR Executor: Exception in task 53.0 in stage 3.0 (TID 56)\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "\tat java.lang.AbstractStringBuilder.<init>(AbstractStringBuilder.java:68)\n",
      "\tat java.lang.StringBuilder.<init>(StringBuilder.java:106)\n",
      "\tat scala.collection.mutable.StringBuilder.<init>(StringBuilder.scala:52)\n",
      "\tat scala.collection.mutable.StringBuilder.<init>(StringBuilder.scala:65)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.Block$.org$apache$spark$sql$catalyst$expressions$codegen$Block$$foldLiteralArgs(javaCode.scala:256)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.Block$BlockHelper$.code$extension(javaCode.scala:243)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.BoundReference.doGenCode(BoundAttribute.scala:58)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.Expression.$anonfun$genCode$3(Expression.scala:151)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.Expression$$Lambda$2594/1968334508.apply(Unknown Source)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.Expression.genCode(Expression.scala:146)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext.$anonfun$generateExpressions$1(CodeGenerator.scala:1272)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext$$Lambda$2592/1628572653.apply(Unknown Source)\n",
      "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n",
      "\tat scala.collection.TraversableLike$$Lambda$56/643290333.apply(Unknown Source)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n",
      "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n",
      "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext.generateExpressions(CodeGenerator.scala:1272)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.createCode(GenerateUnsafeProjection.scala:290)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.create(GenerateUnsafeProjection.scala:338)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.generate(GenerateUnsafeProjection.scala:327)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.UnsafeProjection$.createCodeGeneratedObject(Projection.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.UnsafeProjection$.createCodeGeneratedObject(Projection.scala:119)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.CodeGeneratorWithInterpretedFallback.createObject(CodeGeneratorWithInterpretedFallback.scala:52)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.UnsafeProjection$.create(Projection.scala:150)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.UnsafeProjection$.create(Projection.scala:143)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.UnsafeProjection$.create(Projection.scala:135)\n",
      "\tat org.apache.spark.sql.execution.FileSourceScanExec.$anonfun$doExecute$3(DataSourceScanExec.scala:527)\n",
      "23/01/09 09:44:57 ERROR Executor: Exception in task 58.0 in stage 3.0 (TID 61)\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "\tat java.util.Arrays.copyOfRange(Arrays.java:3664)\n",
      "\tat java.lang.String.<init>(String.java:207)\n",
      "\tat java.lang.StringBuilder.toString(StringBuilder.java:412)\n",
      "\tat org.apache.spark.sql.catalyst.rules.PlanChangeLogger.logMetrics(RuleExecutor.scala:96)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:269)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.$anonfun$canonicalize$1(GenerateUnsafeProjection.scala:319)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$$$Lambda$2930/1549267291.apply(Unknown Source)\n",
      "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n",
      "\tat scala.collection.TraversableLike$$Lambda$56/643290333.apply(Unknown Source)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38)\n",
      "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n",
      "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n",
      "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.canonicalize(GenerateUnsafeProjection.scala:319)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.generate(GenerateUnsafeProjection.scala:327)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.UnsafeProjection$.createCodeGeneratedObject(Projection.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.UnsafeProjection$.createCodeGeneratedObject(Projection.scala:119)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.CodeGeneratorWithInterpretedFallback.createObject(CodeGeneratorWithInterpretedFallback.scala:52)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.UnsafeProjection$.create(Projection.scala:150)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.UnsafeProjection$.create(Projection.scala:143)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.UnsafeProjection$.create(Projection.scala:135)\n",
      "\tat org.apache.spark.sql.execution.FileSourceScanExec.$anonfun$doExecute$3(DataSourceScanExec.scala:527)\n",
      "\tat org.apache.spark.sql.execution.FileSourceScanExec.$anonfun$doExecute$3$adapted(DataSourceScanExec.scala:526)\n",
      "\tat org.apache.spark.sql.execution.FileSourceScanExec$$Lambda$2918/163370093.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2(RDD.scala:877)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2$adapted(RDD.scala:877)\n",
      "\tat org.apache.spark.rdd.RDD$$Lambda$2919/976173826.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "23/01/09 09:45:04 ERROR Executor: Exception in task 22.0 in stage 3.0 (TID 25)\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:45:10 ERROR Executor: Exception in task 35.0 in stage 3.0 (TID 38)\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                       (0 + 72) / 400]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/09 09:45:17 ERROR Executor: Exception in task 26.0 in stage 3.0 (TID 29)\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:45:22 ERROR Executor: Exception in task 69.0 in stage 3.0 (TID 72)\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:45:28 ERROR Executor: Exception in task 1.0 in stage 3.0 (TID 4)\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:45:33 ERROR Executor: Exception in task 5.0 in stage 3.0 (TID 8)\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:45:41 ERROR Executor: Exception in task 19.0 in stage 3.0 (TID 22)\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:45:45 ERROR Executor: Exception in task 33.0 in stage 3.0 (TID 36)\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:45:50 ERROR Executor: Exception in task 67.0 in stage 3.0 (TID 70)\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:45:56 ERROR Executor: Exception in task 11.0 in stage 3.0 (TID 14)\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:45:59 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 19.0 in stage 3.0 (TID 22),5,main]\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:45:59 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 26.0 in stage 3.0 (TID 29),5,main]\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:45:59 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 69.0 in stage 3.0 (TID 72),5,main]\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:46:00 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 5.0 in stage 3.0 (TID 8),5,main]\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:46:00 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 35.0 in stage 3.0 (TID 38),5,main]\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:46:00 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 22.0 in stage 3.0 (TID 25),5,main]\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:46:00 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 33.0 in stage 3.0 (TID 36),5,main]\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:45:59 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 58.0 in stage 3.0 (TID 61),5,main]\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "\tat java.util.Arrays.copyOfRange(Arrays.java:3664)\n",
      "\tat java.lang.String.<init>(String.java:207)\n",
      "\tat java.lang.StringBuilder.toString(StringBuilder.java:412)\n",
      "\tat org.apache.spark.sql.catalyst.rules.PlanChangeLogger.logMetrics(RuleExecutor.scala:96)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:269)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.$anonfun$canonicalize$1(GenerateUnsafeProjection.scala:319)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$$$Lambda$2930/1549267291.apply(Unknown Source)\n",
      "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n",
      "\tat scala.collection.TraversableLike$$Lambda$56/643290333.apply(Unknown Source)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38)\n",
      "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n",
      "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n",
      "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.canonicalize(GenerateUnsafeProjection.scala:319)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.generate(GenerateUnsafeProjection.scala:327)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.UnsafeProjection$.createCodeGeneratedObject(Projection.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.UnsafeProjection$.createCodeGeneratedObject(Projection.scala:119)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.CodeGeneratorWithInterpretedFallback.createObject(CodeGeneratorWithInterpretedFallback.scala:52)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.UnsafeProjection$.create(Projection.scala:150)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.UnsafeProjection$.create(Projection.scala:143)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.UnsafeProjection$.create(Projection.scala:135)\n",
      "\tat org.apache.spark.sql.execution.FileSourceScanExec.$anonfun$doExecute$3(DataSourceScanExec.scala:527)\n",
      "\tat org.apache.spark.sql.execution.FileSourceScanExec.$anonfun$doExecute$3$adapted(DataSourceScanExec.scala:526)\n",
      "\tat org.apache.spark.sql.execution.FileSourceScanExec$$Lambda$2918/163370093.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2(RDD.scala:877)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2$adapted(RDD.scala:877)\n",
      "\tat org.apache.spark.rdd.RDD$$Lambda$2919/976173826.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "23/01/09 09:46:00 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 53.0 in stage 3.0 (TID 56),5,main]\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "\tat java.lang.AbstractStringBuilder.<init>(AbstractStringBuilder.java:68)\n",
      "\tat java.lang.StringBuilder.<init>(StringBuilder.java:106)\n",
      "\tat scala.collection.mutable.StringBuilder.<init>(StringBuilder.scala:52)\n",
      "\tat scala.collection.mutable.StringBuilder.<init>(StringBuilder.scala:65)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.Block$.org$apache$spark$sql$catalyst$expressions$codegen$Block$$foldLiteralArgs(javaCode.scala:256)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.Block$BlockHelper$.code$extension(javaCode.scala:243)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.BoundReference.doGenCode(BoundAttribute.scala:58)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.Expression.$anonfun$genCode$3(Expression.scala:151)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.Expression$$Lambda$2594/1968334508.apply(Unknown Source)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.Expression.genCode(Expression.scala:146)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext.$anonfun$generateExpressions$1(CodeGenerator.scala:1272)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext$$Lambda$2592/1628572653.apply(Unknown Source)\n",
      "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\n",
      "\tat scala.collection.TraversableLike$$Lambda$56/643290333.apply(Unknown Source)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\n",
      "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\n",
      "\tat scala.collection.AbstractTraversable.map(Traversable.scala:108)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.CodegenContext.generateExpressions(CodeGenerator.scala:1272)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.createCode(GenerateUnsafeProjection.scala:290)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.create(GenerateUnsafeProjection.scala:338)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.generate(GenerateUnsafeProjection.scala:327)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.UnsafeProjection$.createCodeGeneratedObject(Projection.scala:123)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.UnsafeProjection$.createCodeGeneratedObject(Projection.scala:119)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.CodeGeneratorWithInterpretedFallback.createObject(CodeGeneratorWithInterpretedFallback.scala:52)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.UnsafeProjection$.create(Projection.scala:150)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.UnsafeProjection$.create(Projection.scala:143)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.UnsafeProjection$.create(Projection.scala:135)\n",
      "\tat org.apache.spark.sql.execution.FileSourceScanExec.$anonfun$doExecute$3(DataSourceScanExec.scala:527)\n",
      "23/01/09 09:46:05 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 1.0 in stage 3.0 (TID 4),5,main]\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:46:00 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 67.0 in stage 3.0 (TID 70),5,main]\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:46:05 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 11.0 in stage 3.0 (TID 14),5,main]\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:46:05 ERROR Executor: Exception in task 25.0 in stage 3.0 (TID 28)\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:46:06 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 25.0 in stage 3.0 (TID 28),5,main]\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                       (0 + 72) / 400]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/09 09:46:14 ERROR Executor: Exception in task 36.0 in stage 3.0 (TID 39)\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:46:14 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 36.0 in stage 3.0 (TID 39),5,main]\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:46:20 ERROR Executor: Exception in task 34.0 in stage 3.0 (TID 37)\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:46:20 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 34.0 in stage 3.0 (TID 37),5,main]\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:46:27 ERROR Executor: Exception in task 39.0 in stage 3.0 (TID 42)\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:46:28 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 39.0 in stage 3.0 (TID 42),5,main]\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:46:34 ERROR Executor: Exception in task 47.0 in stage 3.0 (TID 50)\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:46:34 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 47.0 in stage 3.0 (TID 50),5,main]\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:46:34 WARN ShutdownHookManager: ShutdownHook '$anon$2' timeout, java.util.concurrent.TimeoutException\n",
      "java.util.concurrent.TimeoutException\n",
      "\tat java.util.concurrent.FutureTask.get(FutureTask.java:205)\n",
      "\tat org.apache.hadoop.util.ShutdownHookManager.executeShutdown(ShutdownHookManager.java:124)\n",
      "\tat org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:95)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                       (0 + 73) / 400]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/09 09:46:42 WARN TaskSetManager: Lost task 19.0 in stage 3.0 (TID 22) (aep12.eng.memverge.com executor driver): java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "\n",
      "23/01/09 09:46:42 ERROR Executor: Exception in task 57.0 in stage 3.0 (TID 60)\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:46:42 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 57.0 in stage 3.0 (TID 60),5,main]\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:46:42 ERROR Inbox: Ignoring error\n",
      "java.util.concurrent.RejectedExecutionException: Task org.apache.spark.executor.Executor$TaskRunner@5035c51c rejected from java.util.concurrent.ThreadPoolExecutor@380b80a7[Shutting down, pool size = 64, active threads = 64, queued tasks = 0, completed tasks = 11]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)\n",
      "\tat org.apache.spark.executor.Executor.launchTask(Executor.scala:305)\n",
      "\tat org.apache.spark.scheduler.local.LocalEndpoint.$anonfun$reviveOffers$1(LocalSchedulerBackend.scala:93)\n",
      "\tat org.apache.spark.scheduler.local.LocalEndpoint.$anonfun$reviveOffers$1$adapted(LocalSchedulerBackend.scala:91)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
      "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
      "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n",
      "\tat org.apache.spark.scheduler.local.LocalEndpoint.reviveOffers(LocalSchedulerBackend.scala:91)\n",
      "\tat org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:74)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/01/09 09:46:48 ERROR TaskSetManager: Task 19 in stage 3.0 failed 1 times; aborting job\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                       (0 + 72) / 400]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/09 09:46:53 ERROR Executor: Exception in task 63.0 in stage 3.0 (TID 66)\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:46:53 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 63.0 in stage 3.0 (TID 66),5,main]\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:47:01 ERROR Executor: Exception in task 55.0 in stage 3.0 (TID 58)\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:47:01 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 55.0 in stage 3.0 (TID 58),5,main]\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:47:07 ERROR Executor: Exception in task 4.0 in stage 3.0 (TID 7)\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
      "23/01/09 09:47:07 WARN ShutdownHookManager: ShutdownHook 'ClientFinalizer' timeout, java.util.concurrent.TimeoutException\n",
      "java.util.concurrent.TimeoutException\n",
      "\tat java.util.concurrent.FutureTask.get(FutureTask.java:205)\n",
      "\tat org.apache.hadoop.util.ShutdownHookManager.executeShutdown(ShutdownHookManager.java:124)\n",
      "\tat org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:95)\n",
      "23/01/09 09:47:07 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 4.0 in stage 3.0 (TID 7),5,main]\n",
      "java.lang.OutOfMemoryError: GC overhead limit exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zhongw/.conda/envs/pyspark/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/zhongw/.conda/envs/pyspark/lib/python3.10/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/home/zhongw/.conda/envs/pyspark/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IndexedRow, IndexedRowMatrix\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# this takes 64.6 hrs + 50.3 hrs\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m a1 \u001b[38;5;241m=\u001b[39m \u001b[43mIndexedRowMatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mIndexedRow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoCoordinateMatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m a2 \u001b[38;5;241m=\u001b[39m IndexedRowMatrix(a2\u001b[38;5;241m.\u001b[39mrdd\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m row: IndexedRow(\u001b[38;5;241m*\u001b[39mrow)))\u001b[38;5;241m.\u001b[39mtoCoordinateMatrix()\n",
      "File \u001b[0;32m~/.conda/envs/pyspark/lib/python3.10/site-packages/pyspark/mllib/linalg/distributed.py:772\u001b[0m, in \u001b[0;36mIndexedRowMatrix.toCoordinateMatrix\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtoCoordinateMatrix\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoordinateMatrix\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    761\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;124;03m    Convert this matrix to a CoordinateMatrix.\u001b[39;00m\n\u001b[1;32m    763\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;124;03m    [MatrixEntry(0, 0, 1.0), MatrixEntry(0, 1, 0.0), MatrixEntry(6, 0, 0.0)]\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 772\u001b[0m     java_coordinate_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_matrix_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtoCoordinateMatrix\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m CoordinateMatrix(java_coordinate_matrix)\n",
      "File \u001b[0;32m~/.conda/envs/pyspark/lib/python3.10/site-packages/pyspark/mllib/common.py:157\u001b[0m, in \u001b[0;36mJavaModelWrapper.call\u001b[0;34m(self, name, *a)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39ma: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;124;03m\"\"\"Call method of java_model\"\"\"\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallJavaFunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pyspark/lib/python3.10/site-packages/pyspark/mllib/common.py:131\u001b[0m, in \u001b[0;36mcallJavaFunc\u001b[0;34m(sc, func, *args)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m\"\"\"Call Java Function\"\"\"\u001b[39;00m\n\u001b[1;32m    130\u001b[0m java_args \u001b[38;5;241m=\u001b[39m [_py2java(sc, a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _java2py(sc, \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mjava_args\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.conda/envs/pyspark/lib/python3.10/site-packages/py4j/java_gateway.py:1320\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1313\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/.conda/envs/pyspark/lib/python3.10/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m~/.conda/envs/pyspark/lib/python3.10/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pyspark/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.linalg.distributed import IndexedRow, IndexedRowMatrix\n",
    "# this takes 64.6 hrs + 50.3 hrs\n",
    "a1 = IndexedRowMatrix(a1.rdd.map(lambda row: IndexedRow(*row))).toCoordinateMatrix()\n",
    "a2 = IndexedRowMatrix(a2.rdd.map(lambda row: IndexedRow(*row))).toCoordinateMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2299b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 =(spark\n",
    " .createDataFrame(a1.transpose().entries)\n",
    " .where(F.col('value')>0)\n",
    " .toDF('sample', 'rsID', 'code')\n",
    ")\n",
    "a2 =(spark\n",
    " .createDataFrame(a2.transpose().entries)\n",
    " .where(F.col('value')>0)\n",
    " .toDF('sample', 'rsID', 'code')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085529f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the genotype sparse matrix\n",
    "# rows are samples\n",
    "# columns are genotype (rsID:gt)\n",
    "# values are doses (how many alleles)\n",
    "gt = a1.union(a2)\n",
    "gt = (gt\n",
    "      .withColumn('index', F.concat_ws(':', *['rsID', 'code']))\n",
    "      .withColumn('dose', F.lit(1.0))\n",
    "      .select('sample', 'index', 'dose')\n",
    "      .groupby('sample', 'index')\n",
    "      .agg(F.sum('dose').alias('dose'))\n",
    "     )\n",
    "\n",
    "gt.write.mode('overwrite').parquet('1kgenome_gt_coo.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e97704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c276005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/23 14:12:38 WARN DAGScheduler: Broadcasting large task binary with size 1787.1 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:=====================================================>(799 + 1) / 800]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/08 02:01:33 WARN DAGScheduler: Broadcasting large task binary with size 1794.7 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:=====================================================>(199 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/08 04:01:07 WARN DAGScheduler: Broadcasting large task binary with size 1792.1 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/08 04:30:14 ERROR Executor: Exception in task 0.0 in stage 21.0 (TID 2209)\n",
      "org.apache.spark.SparkException: Kryo serialization failed: Buffer overflow. Available: 0, required: 6\n",
      "Serialization trace:\n",
      "_data (org.apache.spark.util.collection.OpenHashSet)\n",
      "org$apache$spark$util$collection$OpenHashMap$$_keySet (org.apache.spark.util.collection.OpenHashMap$mcJ$sp). To avoid this, increase spark.kryoserializer.buffer.max value.\n",
      "\tat org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:391)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.aggregate.ComplexTypedAggregateExpression.eval(TypedAggregateExpression.scala:260)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.aggregate.TypedImperativeAggregate.eval(interfaces.scala:594)\n",
      "\tat org.apache.spark.sql.execution.aggregate.AggregationIterator.$anonfun$generateResultProjection$5(AggregationIterator.scala:257)\n",
      "\tat org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.next(ObjectAggregationIterator.scala:96)\n",
      "\tat org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.next(ObjectAggregationIterator.scala:32)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:365)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: com.esotericsoftware.kryo.KryoException: Buffer overflow. Available: 0, required: 6\n",
      "Serialization trace:\n",
      "_data (org.apache.spark.util.collection.OpenHashSet)\n",
      "org$apache$spark$util$collection$OpenHashMap$$_keySet (org.apache.spark.util.collection.OpenHashMap$mcJ$sp)\n",
      "\tat com.esotericsoftware.kryo.io.Output.require(Output.java:167)\n",
      "\tat com.esotericsoftware.kryo.io.Output.writeAscii_slow(Output.java:499)\n",
      "\tat com.esotericsoftware.kryo.io.Output.writeString(Output.java:348)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultSerializers$StringSerializer.write(DefaultSerializers.java:195)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultSerializers$StringSerializer.write(DefaultSerializers.java:188)\n",
      "\tat com.esotericsoftware.kryo.Kryo.writeObjectOrNull(Kryo.java:629)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$StringArraySerializer.write(DefaultArraySerializers.java:272)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$StringArraySerializer.write(DefaultArraySerializers.java:258)\n",
      "\tat com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575)\n",
      "\tat com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:79)\n",
      "\tat com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508)\n",
      "\tat com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575)\n",
      "\tat com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:79)\n",
      "\tat com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508)\n",
      "\tat com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:651)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:361)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:302)\n",
      "\tat com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:651)\n",
      "\tat org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:387)\n",
      "\t... 20 more\n",
      "23/01/08 04:30:14 WARN TaskSetManager: Lost task 0.0 in stage 21.0 (TID 2209) (aep12.eng.memverge.com executor driver): org.apache.spark.SparkException: Kryo serialization failed: Buffer overflow. Available: 0, required: 6\n",
      "Serialization trace:\n",
      "_data (org.apache.spark.util.collection.OpenHashSet)\n",
      "org$apache$spark$util$collection$OpenHashMap$$_keySet (org.apache.spark.util.collection.OpenHashMap$mcJ$sp). To avoid this, increase spark.kryoserializer.buffer.max value.\n",
      "\tat org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:391)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.aggregate.ComplexTypedAggregateExpression.eval(TypedAggregateExpression.scala:260)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.aggregate.TypedImperativeAggregate.eval(interfaces.scala:594)\n",
      "\tat org.apache.spark.sql.execution.aggregate.AggregationIterator.$anonfun$generateResultProjection$5(AggregationIterator.scala:257)\n",
      "\tat org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.next(ObjectAggregationIterator.scala:96)\n",
      "\tat org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.next(ObjectAggregationIterator.scala:32)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:365)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: com.esotericsoftware.kryo.KryoException: Buffer overflow. Available: 0, required: 6\n",
      "Serialization trace:\n",
      "_data (org.apache.spark.util.collection.OpenHashSet)\n",
      "org$apache$spark$util$collection$OpenHashMap$$_keySet (org.apache.spark.util.collection.OpenHashMap$mcJ$sp)\n",
      "\tat com.esotericsoftware.kryo.io.Output.require(Output.java:167)\n",
      "\tat com.esotericsoftware.kryo.io.Output.writeAscii_slow(Output.java:499)\n",
      "\tat com.esotericsoftware.kryo.io.Output.writeString(Output.java:348)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultSerializers$StringSerializer.write(DefaultSerializers.java:195)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultSerializers$StringSerializer.write(DefaultSerializers.java:188)\n",
      "\tat com.esotericsoftware.kryo.Kryo.writeObjectOrNull(Kryo.java:629)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$StringArraySerializer.write(DefaultArraySerializers.java:272)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$StringArraySerializer.write(DefaultArraySerializers.java:258)\n",
      "\tat com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575)\n",
      "\tat com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:79)\n",
      "\tat com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508)\n",
      "\tat com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575)\n",
      "\tat com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:79)\n",
      "\tat com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508)\n",
      "\tat com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:651)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:361)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:302)\n",
      "\tat com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:651)\n",
      "\tat org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:387)\n",
      "\t... 20 more\n",
      "\n",
      "23/01/08 04:30:14 ERROR TaskSetManager: Task 0 in stage 21.0 failed 1 times; aborting job\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o30348.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 21.0 failed 1 times, most recent failure: Lost task 0.0 in stage 21.0 (TID 2209) (aep12.eng.memverge.com executor driver): org.apache.spark.SparkException: Kryo serialization failed: Buffer overflow. Available: 0, required: 6\nSerialization trace:\n_data (org.apache.spark.util.collection.OpenHashSet)\norg$apache$spark$util$collection$OpenHashMap$$_keySet (org.apache.spark.util.collection.OpenHashMap$mcJ$sp). To avoid this, increase spark.kryoserializer.buffer.max value.\n\tat org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:391)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)\n\tat org.apache.spark.sql.execution.aggregate.ComplexTypedAggregateExpression.eval(TypedAggregateExpression.scala:260)\n\tat org.apache.spark.sql.catalyst.expressions.aggregate.TypedImperativeAggregate.eval(interfaces.scala:594)\n\tat org.apache.spark.sql.execution.aggregate.AggregationIterator.$anonfun$generateResultProjection$5(AggregationIterator.scala:257)\n\tat org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.next(ObjectAggregationIterator.scala:96)\n\tat org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.next(ObjectAggregationIterator.scala:32)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:365)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: com.esotericsoftware.kryo.KryoException: Buffer overflow. Available: 0, required: 6\nSerialization trace:\n_data (org.apache.spark.util.collection.OpenHashSet)\norg$apache$spark$util$collection$OpenHashMap$$_keySet (org.apache.spark.util.collection.OpenHashMap$mcJ$sp)\n\tat com.esotericsoftware.kryo.io.Output.require(Output.java:167)\n\tat com.esotericsoftware.kryo.io.Output.writeAscii_slow(Output.java:499)\n\tat com.esotericsoftware.kryo.io.Output.writeString(Output.java:348)\n\tat com.esotericsoftware.kryo.serializers.DefaultSerializers$StringSerializer.write(DefaultSerializers.java:195)\n\tat com.esotericsoftware.kryo.serializers.DefaultSerializers$StringSerializer.write(DefaultSerializers.java:188)\n\tat com.esotericsoftware.kryo.Kryo.writeObjectOrNull(Kryo.java:629)\n\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$StringArraySerializer.write(DefaultArraySerializers.java:272)\n\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$StringArraySerializer.write(DefaultArraySerializers.java:258)\n\tat com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575)\n\tat com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:79)\n\tat com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508)\n\tat com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575)\n\tat com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:79)\n\tat com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508)\n\tat com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:651)\n\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:361)\n\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:302)\n\tat com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:651)\n\tat org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:387)\n\t... 20 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2228)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2268)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2293)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1021)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1020)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:424)\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$executeCollect$1(AdaptiveSparkPlanExec.scala:340)\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.withFinalPlanUpdate(AdaptiveSparkPlanExec.scala:368)\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.executeCollect(AdaptiveSparkPlanExec.scala:340)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3868)\n\tat org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:3120)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:3858)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:510)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3856)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3856)\n\tat org.apache.spark.sql.Dataset.collect(Dataset.scala:3120)\n\tat org.apache.spark.ml.feature.StringIndexer.countByValue(StringIndexer.scala:204)\n\tat org.apache.spark.ml.feature.StringIndexer.sortByFreq(StringIndexer.scala:212)\n\tat org.apache.spark.ml.feature.StringIndexer.fit(StringIndexer.scala:242)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Kryo serialization failed: Buffer overflow. Available: 0, required: 6\nSerialization trace:\n_data (org.apache.spark.util.collection.OpenHashSet)\norg$apache$spark$util$collection$OpenHashMap$$_keySet (org.apache.spark.util.collection.OpenHashMap$mcJ$sp). To avoid this, increase spark.kryoserializer.buffer.max value.\n\tat org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:391)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)\n\tat org.apache.spark.sql.execution.aggregate.ComplexTypedAggregateExpression.eval(TypedAggregateExpression.scala:260)\n\tat org.apache.spark.sql.catalyst.expressions.aggregate.TypedImperativeAggregate.eval(interfaces.scala:594)\n\tat org.apache.spark.sql.execution.aggregate.AggregationIterator.$anonfun$generateResultProjection$5(AggregationIterator.scala:257)\n\tat org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.next(ObjectAggregationIterator.scala:96)\n\tat org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.next(ObjectAggregationIterator.scala:32)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:365)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: com.esotericsoftware.kryo.KryoException: Buffer overflow. Available: 0, required: 6\nSerialization trace:\n_data (org.apache.spark.util.collection.OpenHashSet)\norg$apache$spark$util$collection$OpenHashMap$$_keySet (org.apache.spark.util.collection.OpenHashMap$mcJ$sp)\n\tat com.esotericsoftware.kryo.io.Output.require(Output.java:167)\n\tat com.esotericsoftware.kryo.io.Output.writeAscii_slow(Output.java:499)\n\tat com.esotericsoftware.kryo.io.Output.writeString(Output.java:348)\n\tat com.esotericsoftware.kryo.serializers.DefaultSerializers$StringSerializer.write(DefaultSerializers.java:195)\n\tat com.esotericsoftware.kryo.serializers.DefaultSerializers$StringSerializer.write(DefaultSerializers.java:188)\n\tat com.esotericsoftware.kryo.Kryo.writeObjectOrNull(Kryo.java:629)\n\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$StringArraySerializer.write(DefaultArraySerializers.java:272)\n\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$StringArraySerializer.write(DefaultArraySerializers.java:258)\n\tat com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575)\n\tat com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:79)\n\tat com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508)\n\tat com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575)\n\tat com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:79)\n\tat com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508)\n\tat com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:651)\n\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:361)\n\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:302)\n\tat com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:651)\n\tat org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:387)\n\t... 20 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringIndexer\n\u001b[1;32m      3\u001b[0m indexx \u001b[38;5;241m=\u001b[39m gt\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[43mStringIndexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputCol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputCol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mi\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m indexx \u001b[38;5;241m=\u001b[39m indexer\u001b[38;5;241m.\u001b[39mtransform(indexx)\n\u001b[1;32m      6\u001b[0m gt \u001b[38;5;241m=\u001b[39m gt\u001b[38;5;241m.\u001b[39mjoin(indexx, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdose\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/pyspark/lib/python3.10/site-packages/pyspark/ml/base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[1;32m    210\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/pyspark/lib/python3.10/site-packages/pyspark/ml/wrapper.py:379\u001b[0m, in \u001b[0;36mJavaEstimator._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset: DataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JM:\n\u001b[0;32m--> 379\u001b[0m     java_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_java\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_model(java_model)\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_copyValues(model)\n",
      "File \u001b[0;32m~/.conda/envs/pyspark/lib/python3.10/site-packages/pyspark/ml/wrapper.py:376\u001b[0m, in \u001b[0;36mJavaEstimator._fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[0;32m--> 376\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pyspark/lib/python3.10/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/.conda/envs/pyspark/lib/python3.10/site-packages/pyspark/sql/utils.py:190\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    192\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/.conda/envs/pyspark/lib/python3.10/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o30348.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 21.0 failed 1 times, most recent failure: Lost task 0.0 in stage 21.0 (TID 2209) (aep12.eng.memverge.com executor driver): org.apache.spark.SparkException: Kryo serialization failed: Buffer overflow. Available: 0, required: 6\nSerialization trace:\n_data (org.apache.spark.util.collection.OpenHashSet)\norg$apache$spark$util$collection$OpenHashMap$$_keySet (org.apache.spark.util.collection.OpenHashMap$mcJ$sp). To avoid this, increase spark.kryoserializer.buffer.max value.\n\tat org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:391)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)\n\tat org.apache.spark.sql.execution.aggregate.ComplexTypedAggregateExpression.eval(TypedAggregateExpression.scala:260)\n\tat org.apache.spark.sql.catalyst.expressions.aggregate.TypedImperativeAggregate.eval(interfaces.scala:594)\n\tat org.apache.spark.sql.execution.aggregate.AggregationIterator.$anonfun$generateResultProjection$5(AggregationIterator.scala:257)\n\tat org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.next(ObjectAggregationIterator.scala:96)\n\tat org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.next(ObjectAggregationIterator.scala:32)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:365)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: com.esotericsoftware.kryo.KryoException: Buffer overflow. Available: 0, required: 6\nSerialization trace:\n_data (org.apache.spark.util.collection.OpenHashSet)\norg$apache$spark$util$collection$OpenHashMap$$_keySet (org.apache.spark.util.collection.OpenHashMap$mcJ$sp)\n\tat com.esotericsoftware.kryo.io.Output.require(Output.java:167)\n\tat com.esotericsoftware.kryo.io.Output.writeAscii_slow(Output.java:499)\n\tat com.esotericsoftware.kryo.io.Output.writeString(Output.java:348)\n\tat com.esotericsoftware.kryo.serializers.DefaultSerializers$StringSerializer.write(DefaultSerializers.java:195)\n\tat com.esotericsoftware.kryo.serializers.DefaultSerializers$StringSerializer.write(DefaultSerializers.java:188)\n\tat com.esotericsoftware.kryo.Kryo.writeObjectOrNull(Kryo.java:629)\n\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$StringArraySerializer.write(DefaultArraySerializers.java:272)\n\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$StringArraySerializer.write(DefaultArraySerializers.java:258)\n\tat com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575)\n\tat com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:79)\n\tat com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508)\n\tat com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575)\n\tat com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:79)\n\tat com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508)\n\tat com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:651)\n\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:361)\n\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:302)\n\tat com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:651)\n\tat org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:387)\n\t... 20 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2228)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2268)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2293)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1021)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1020)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:424)\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$executeCollect$1(AdaptiveSparkPlanExec.scala:340)\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.withFinalPlanUpdate(AdaptiveSparkPlanExec.scala:368)\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.executeCollect(AdaptiveSparkPlanExec.scala:340)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3868)\n\tat org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:3120)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:3858)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:510)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3856)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3856)\n\tat org.apache.spark.sql.Dataset.collect(Dataset.scala:3120)\n\tat org.apache.spark.ml.feature.StringIndexer.countByValue(StringIndexer.scala:204)\n\tat org.apache.spark.ml.feature.StringIndexer.sortByFreq(StringIndexer.scala:212)\n\tat org.apache.spark.ml.feature.StringIndexer.fit(StringIndexer.scala:242)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Kryo serialization failed: Buffer overflow. Available: 0, required: 6\nSerialization trace:\n_data (org.apache.spark.util.collection.OpenHashSet)\norg$apache$spark$util$collection$OpenHashMap$$_keySet (org.apache.spark.util.collection.OpenHashMap$mcJ$sp). To avoid this, increase spark.kryoserializer.buffer.max value.\n\tat org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:391)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)\n\tat org.apache.spark.sql.execution.aggregate.ComplexTypedAggregateExpression.eval(TypedAggregateExpression.scala:260)\n\tat org.apache.spark.sql.catalyst.expressions.aggregate.TypedImperativeAggregate.eval(interfaces.scala:594)\n\tat org.apache.spark.sql.execution.aggregate.AggregationIterator.$anonfun$generateResultProjection$5(AggregationIterator.scala:257)\n\tat org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.next(ObjectAggregationIterator.scala:96)\n\tat org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.next(ObjectAggregationIterator.scala:32)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:365)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: com.esotericsoftware.kryo.KryoException: Buffer overflow. Available: 0, required: 6\nSerialization trace:\n_data (org.apache.spark.util.collection.OpenHashSet)\norg$apache$spark$util$collection$OpenHashMap$$_keySet (org.apache.spark.util.collection.OpenHashMap$mcJ$sp)\n\tat com.esotericsoftware.kryo.io.Output.require(Output.java:167)\n\tat com.esotericsoftware.kryo.io.Output.writeAscii_slow(Output.java:499)\n\tat com.esotericsoftware.kryo.io.Output.writeString(Output.java:348)\n\tat com.esotericsoftware.kryo.serializers.DefaultSerializers$StringSerializer.write(DefaultSerializers.java:195)\n\tat com.esotericsoftware.kryo.serializers.DefaultSerializers$StringSerializer.write(DefaultSerializers.java:188)\n\tat com.esotericsoftware.kryo.Kryo.writeObjectOrNull(Kryo.java:629)\n\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$StringArraySerializer.write(DefaultArraySerializers.java:272)\n\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$StringArraySerializer.write(DefaultArraySerializers.java:258)\n\tat com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575)\n\tat com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:79)\n\tat com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508)\n\tat com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575)\n\tat com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:79)\n\tat com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508)\n\tat com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:651)\n\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:361)\n\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:302)\n\tat com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:651)\n\tat org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:387)\n\t... 20 more\n"
     ]
    }
   ],
   "source": [
    "# create indexer\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "indexx = gt.select('index')\n",
    "indexer = StringIndexer(inputCol='index', outputCol='i').fit(indexx)\n",
    "indexx = indexer.transform(indexx)\n",
    "gt = gt.join(indexx, on='index', how='left').select('index', 'sample', 'i', 'dose')\n",
    "gt.write.mode('overwrite').parquet('1kgenome_gt_indexed_coo.pq')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9f4e5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/08 10:35:49 WARN DAGScheduler: Broadcasting large task binary with size 1795.1 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.              (0 + 72) / 800]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zhongw/.conda/envs/pyspark/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/zhongw/.conda/envs/pyspark/lib/python3.10/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/home/zhongw/.conda/envs/pyspark/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pyspark/lib/python3.10/site-packages/pyspark/sql/dataframe.py:606\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a bool\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[0;32m--> 606\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/pyspark/lib/python3.10/site-packages/py4j/java_gateway.py:1320\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1313\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/.conda/envs/pyspark/lib/python3.10/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m~/.conda/envs/pyspark/lib/python3.10/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pyspark/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gt.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54491359",
   "metadata": {},
   "source": [
    "## 4. Formating GWAS results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433f7a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert alleles to code\n",
    "import pyspark.sql.functions as F\n",
    "genomes = spark.read.parquet('s3a://zhong-active/PGS/1kgenome_dbSNP328.pq')\n",
    "grc37_p13 = spark.read.parquet('s3a://zhong-active/PGS/dbsnp328/dbsnp328_grc37_p13.pq')\n",
    "\n",
    "code = (genomes\n",
    " .select(\n",
    "   F.col('ID').astype('long'),\n",
    "   F.posexplode(F.split(F.concat_ws(',', 'REF', 'ALT'), ',')).alias('code1k', 'allele') \n",
    " )\n",
    " .select('ID', F.col('code1k').astype('int'), 'allele')\n",
    " .join(grc37_p13.select(F.col('rsID').alias('ID'), 'code', 'allele'), on=['ID', 'allele'])\n",
    " .drop('allele')\n",
    " )\n",
    "\n",
    "code.write.mode('overwrite').parquet('s3a://zhong-active/PGS/1kgenome_dbSNP328_code_mapping.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7866d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only need to run this once\n",
    "gwas = 's3a://zhong-active/PGS/shared-dna/notebooks/gwas_2022-11-04.csv.gz'\n",
    "grc37_p13 = 's3a://zhong-active/PGS/dbsnp328/dbsnp328_grc37_p13.pq'\n",
    "grc38_p13 = 's3a://zhong-active/PGS/dbsnp328/dbsnp328_grc38_p13.pq'\n",
    "dbsnp1 = spark.read.parquet(grc37_p13).select('chr', 'pos', 'rsID')\n",
    "dbsnp2 = spark.read.parquet(grc38_p13).select('chr', 'pos', 'rsID')\n",
    "ref = (spark\n",
    "       .read\n",
    "       .csv(gwas, sep='\\t', header=True)\n",
    "       .withColumn('CHR_ID', F.when(F.isnull('CHR_ID'), F.regexp_extract('SNPs', r'chr([\\dXYM]+):(\\d+)', 1)).otherwise(F.col('CHR_ID')))\n",
    "       .withColumn('CHR_POS', F.when(F.isnull('CHR_POS'), F.regexp_extract('SNPs', r'chr([\\dXYM]+):(\\d+)', 2)).otherwise(F.col('CHR_POS')))       \n",
    "       .select(F.col('SNP_ID_CURRENT').astype('long').alias('ID'), \n",
    "               F.col('rallele').alias('alt'),\n",
    "               F.col('OR or BETA').astype('float').alias('OR'),\n",
    "               F.col('CHR_ID').alias('chr'),\n",
    "               F.col('CHR_POS').astype('long').alias('pos'),\n",
    "               F.col('DISEASE/TRAIT').alias('trait'),\n",
    "               F.col('DATE ADDED TO CATALOG').astype('date').alias('date'),\n",
    "               F.col('PUBMEDID').astype('long').alias('pubmedID')\n",
    "       ).where(\n",
    "         (F.col('OR')>0.0)\n",
    "       )\n",
    ")\n",
    "\n",
    "# replace chromosome numbering\n",
    "mapping = {\n",
    "  'X': '23',\n",
    "  'Y': '24',\n",
    "  'M': '25'\n",
    "}\n",
    "mapping.update({str(i+1):str(i+1) for i in range(22)})\n",
    "print(mapping)\n",
    "apply_mapping_udf = F.udf(lambda x: mapping.get(x, x))\n",
    "ref = ref.withColumn('chr', apply_mapping_udf('chr').astype('int'))\n",
    "\n",
    "ref = (ref\n",
    "       .join(dbsnp1, on=['chr', 'pos'], how='left')\n",
    "       .withColumn('ID', F.when(F.isnull('ID'), F.col('rsID')).otherwise(F.col('ID')))\n",
    "       .drop('rsID')\n",
    "       .join(dbsnp2, on=['chr', 'pos'], how='left')\n",
    "       .withColumn('rsID', F.when(F.isnull('ID'), F.col('rsID')).otherwise(F.col('ID')))\n",
    "       .select('trait', 'rsID', 'alt', 'OR', 'pubmedID', 'date')\n",
    "      )               \n",
    "ref = ref.drop_duplicates(['trait', 'rsID', 'alt'])\n",
    "(ref\n",
    " .write\n",
    " .mode('overwrite')\n",
    " .parquet('s3a://zhong-active/PGS/shared-dna/notebooks/gwas_2022-11-04_ORs.pq')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f9c86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8860ad",
   "metadata": {},
   "source": [
    "## 5. Convert gwas to sparse format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b1f85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = spark.read.parquet('s3a://zhong-active/PGS/1kgenome_dbSNP328_code_mapping.pq')\n",
    "ref = spark.read.parquet('s3a://zhong-active/PGS/shared-dna/notebooks/gwas_2022-11-04_ORs.pq')\n",
    "# mapping ref codes to 1kgenome codes\n",
    "ref1k = ref.join(code.select(F.col('ID').alias('rsID'), 'code', 'code1k'), on=['rsID', 'code'], how='left').fillna(0)\n",
    "\n",
    "# create gwas ref sparse matrix\n",
    "# rows are genotype(rsID:gt)\n",
    "# columns are OR\n",
    "\n",
    "ref1k = (ref1k\n",
    " .withColumn('trait', F.concat_ws('|', *['trait', 'pubmedID']))\n",
    " .withColumn('index', F.concat_ws(':', *['rsID', 'code1k']))\n",
    " .select('index', 'trait', 'OR')\n",
    ") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2fcd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create indexer for traits\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "indexer = StringIndexer(inputCol='trait', outputCol='j').fit(ref1k)\n",
    "ref1k = indexer.transform(ref1k).select('index', 'j', 'OR', 'trait')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d518ab1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# match genotypes in reference gwas using the indexed 1kgenome\n",
    "# variants not in the 1kgenome are ignored\n",
    "\n",
    "ref1k = (\n",
    "    ref1k\n",
    "    .join(gt.select('index', 'i'), on='index', how='left')\n",
    "    .fillna({'i': -1})\n",
    "    .where(F.col('i')>=0)\n",
    "    .select('i', 'j', 'OR', 'trait')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea66d55",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# save results\n",
    "ref1k.write.mode('overwrite').parquet('gwas_2022-11-04_ORs_1kgenome_indexed_coo.pq')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc565245",
   "metadata": {},
   "source": [
    "## 6. Sparse score calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fea12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg.distributed import CoordinateMatrix\n",
    "\n",
    "gt = CoordinateMatrix(gt.rdd.map(lambda r: (r[0], r[1], r[2])))\n",
    "gwas = CoordinateMatrix(ref1k.rdd.map(lambda r: (r[0], r[1], r[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b33566",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = gt.toRowMatrix().multiply(gwas.toRowMatrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06558554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the score matrix\n",
    "(spark\n",
    " .createDataFrame(results.entries)\n",
    " .toDF('sample', 'trait', 'score')\n",
    " .write\n",
    " .mode('overwrite')\n",
    " .parquet('s3a://zhong-active/PGS/1kgenome_gwas_scores_coo.pq')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aad81f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
